{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "title: \"Report: PGS Catalog Calculator Pipeline\"\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scorefile metadata\n",
    "with open('log_scorefiles.json', 'r') as jsonfile:\n",
    "    json_scores = json.load(jsonfile)\n",
    "\n",
    "# Load logs\n",
    "paths_log = glob.glob(\"*_summary.csv\")\n",
    "log = pd.concat([pd.read_csv(x) for x in paths_log])\n",
    "\n",
    "# Load PGS data\n",
    "paths_pgs = glob.glob(\"*_pgs.txt.gz\")\n",
    "pgs = pd.concat([pd.read_csv(x, index_col=[0,1], sep='\\t') for x in paths_pgs])\n",
    "\n",
    "# Load PCA/pop sim\n",
    "paths_popsim = glob.glob(\"*_popsimilarity.txt.gz\")\n",
    "popsim = pd.concat([pd.read_csv(x, index_col=[0,1], sep='\\t') for x in paths_popsim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat command.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring file metadata\n",
    "\n",
    "> Additional [documentation](https://pgsc-calc.readthedocs.io/en/latest/output.html#report) is available that explains some of the terms used this report in more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_scores = {}\n",
    "\n",
    "for scorefile, metadata in json_scores.items():\n",
    "    result = {'Polygenic Score ID': np.nan, 'Publication': np.nan, 'Trait': np.nan, 'Number of variants': int(metadata['variants_number']), 'Genome build': np.nan}\n",
    "    \n",
    "    # pgs_id\n",
    "    pgs_id = ''\n",
    "    if pd.isnull(metadata['pgs_id']) == False:\n",
    "        pgs_id += '<a href=\"https://www.pgscatalog.org/score/{}\">{}</a>'.format(metadata['pgs_id'], metadata['pgs_id'])\n",
    "    \n",
    "    if pd.isnull(metadata['pgs_name']) == False:\n",
    "        if pgs_id == '':\n",
    "            pgs_id = metadata['pgs_name']\n",
    "        else:\n",
    "            pgs_id += '<br><small>({})</small>'.format(metadata['pgs_name'])\n",
    "    result['Polygenic Score ID'] = pgs_id\n",
    "    \n",
    "    # pgp_id\n",
    "    pgp_id = ''\n",
    "    if pd.isnull(metadata['pgp_id']) == False:\n",
    "        pgp_id += '<a href=\"https://www.pgscatalog.org/publication/{}\">{}</a>'.format(metadata['pgp_id'], metadata['pgp_id'])\n",
    "    \n",
    "    if pd.isnull(metadata['citation']) == False:\n",
    "        if pgp_id != '':\n",
    "            pgp_id += \"<br>\"\n",
    "        \n",
    "        pgp_id += '<small>{}</small>'.format(metadata['citation'])\n",
    "    \n",
    "    if pgp_id != '':\n",
    "        result['Publication'] = pgp_id\n",
    "        \n",
    "    # trait\n",
    "    # Trait\n",
    "    trait_mapped = ''\n",
    "    if 'trait_efo' in metadata:\n",
    "        urls = []\n",
    "        for efo_id, trait_name in zip(metadata['trait_efo'], metadata['trait_mapped']):\n",
    "            urls.append('<a href=\"http://www.ebi.ac.uk/efo/{}\">{}</a>'.format(efo_id, trait_name))\n",
    "        trait_mapped = '<u>Mapped trait</u>: '\n",
    "        trait_mapped += ', '.join(urls)\n",
    "        \n",
    "    if pd.isnull(metadata['trait_reported']) == False:\n",
    "        trait_reported = '<u>Reported trait</u>: {}'.format(metadata['trait_reported'])\n",
    "    \n",
    "        if trait_mapped == '':\n",
    "            result['Trait'] = trait_reported\n",
    "        else:\n",
    "            result['Trait'] = trait_reported + '<br>' + trait_mapped\n",
    "    \n",
    "    \n",
    "    # Genome build\n",
    "    build_info = '<u>Reported</u>: {}'.format(metadata['genome_build'])\n",
    "    if metadata['use_harmonised'] is True:\n",
    "        build_info += '<br><u>Harmonized Build</u>: {}'.format(metadata['HmPOS_build'])\n",
    "    result['Genome build'] =  build_info\n",
    "  \n",
    "    metadata_scores[scorefile] = result\n",
    "    \n",
    "    \n",
    "metadata_scores = pd.DataFrame.from_dict(metadata_scores, orient='index')\n",
    "metadata_scores.index.name = 'Scoring File'\n",
    "metadata_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "\n",
    "def SummarizeMatching(df):\n",
    "    n_matched = df.loc[df.match_status == 'matched', 'count'].sum()\n",
    "    n_unmatched = df.loc[df.match_status != 'matched', 'count'].sum()\n",
    "    n = n_matched + n_unmatched\n",
    "    \n",
    "    return pd.Series({'perc_matched': 100*n_matched/n, 'n_matched': n_matched, 'n_unmatched': n_unmatched, 'n': n})\n",
    "\n",
    "agg_log = log.groupby(['dataset', 'accession', 'score_pass', 'match_status'])[['count']].sum().reset_index()    \n",
    "summary = agg_log.groupby(['dataset', 'accession', 'score_pass']).apply(SummarizeMatching).reset_index()\n",
    "\n",
    "#Reorder columns & rows\n",
    "summary = summary[['dataset', 'accession', 'n', 'score_pass', 'perc_matched', 'n_matched', 'n_unmatched']].sort_values('perc_matched', ascending=False)\n",
    "\n",
    "# Rename columns\n",
    "names_summary = {\"dataset\": \"Sampleset\", \"accession\": \"Scoring file\", \n",
    "                 \"n\": \"Number of variants\", \n",
    "                 \"score_pass\": \"Passed matching\", \"percent_matched\": \"Match %\", \n",
    "                 \"n_matched\": \"Total matched\", \"n_unmatched\": \"Total unmatched\"\n",
    "                }\n",
    "summary = summary.convert_dtypes().rename(names_summary, axis='columns')\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_log = {\"dataset\": \"Sampleset\", \"accession\": \"Scoring file\",\n",
    "             'match_status': \"Match type\", \"n\": \"Number of variants\", \n",
    "             \"duplicate_best_match\": \"Multiple potential matches\",\n",
    "             \"duplicate_ID\": \"Duplicated matched variants\",\n",
    "             \"ambiguous\": \"Ambiguous\",\n",
    "             \"match_flipped\" : \"Flipped Match\",\n",
    "             \"match_IDs\" : \"Matches Reference IDs\",\n",
    "             \"is_multiallelic\": \"Multiallelic\" ,\n",
    "             'count' : 'N',\n",
    "             \"percent\": \"%\"\n",
    "            }\n",
    "\n",
    "log['match_status'] = log['match_status'].astype('category')\n",
    "log['match_status'] = log['match_status'].cat.reorder_categories([\"matched\", \"excluded\", \"unmatched\"])\n",
    "log = log.sort_values(['accession', 'match_status'])\n",
    "log = log.rename(names_log, axis='columns')\n",
    "log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
