---
title: "PGS Catalog Calculator summary report"
output: html_document
date: "`r Sys.time()`"
params:
  img: PGS_Logo.png
---

```{r setup, include=FALSE}
# sad note: base R + rmarkdown only
# installing the tidyverse is causing me container problems >:(
knitr::opts_chunk$set(echo = TRUE)
library(httr)
library(jsonlite)
library(dplyr)
library(ggplot2)

log_paths <- list.files(pattern = "*_log.csv", full.names = TRUE)

read_log <- function(path) {
  log <- read.csv(path)
  log$match_type <- as.character(log$match_type)
  log$match_type <- ifelse(log$match_type == "", "no match", log$match_type)
  return(log)
}

log <- Reduce(dplyr::bind_rows, lapply(log_paths, read_log))
```

```{r, eval = FALSE, echo=FALSE}
# logo
htmltools::img(src = knitr::image_uri(params$img),
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0; padding:10px;',
               height = "200px")
```

## Metadata {.tabset}

### PGS Catalog scores

```{r, echo = FALSE}
call_api <- function(log) {
  accessions <- trimws(unique(log$accession))
  pgs_ids <- paste(accessions[grepl("^PGS[0-9]{6}", accessions)], collapse = ",")
  api_url <- paste0("https://www.pgscatalog.org/rest/score/search?pgs_ids=", pgs_ids)
  res <- GET(api_url)
  return(fromJSON(rawToChar(res$content)))
}

add_urls <- function(df) {
  df$pgs_id <- paste0('<a href="https://www.pgscatalog.org/score/', df$pgs_id, '">', df$pgs_id, '</a>')
  df$pgp_id <- paste0('<a href="https://www.pgscatalog.org/publication/', df$id, '">', df$id, '</a>')
  df$mapped <- paste0('<a href="', df$url, '">', df$label, '</a>')
  df$url <- df$label <- df$id <- NULL
  return(df)
}

make_publication_table <- function(log) {
  json <- call_api(log)
  
  if (json$size == 0) {
    return(data.frame())
  }
  
  df <- data.frame(pgs_id = json$results$id)
  pubs <- json$results$publication[, c("id", "firstauthor", "journal", "date_publication")]
  traits <- data.frame(reported = json$results$trait_reported,
                       Reduce(dplyr::bind_rows, json$results$trait_efo)[, c("label", "url")],
                       n_variants = json$results$variants_number)
  unformatted <- dplyr::bind_cols(df, pubs, traits)
  formatted <- add_urls(tidyr::unite(unformatted, "Publication", firstauthor:date_publication, sep = " "))
  
  return(formatted[, c("pgs_id", "pgp_id", "Publication", "reported", "mapped", "n_variants")])
}

meta_tab <- make_publication_table(log)

if (nrow(meta_tab) > 0) {
  DT::datatable(meta_tab, escape = FALSE,
              colnames = c("Polygenic Score ID" = "pgs_id", "PGS Publication ID"= "pgp_id", "Reported Trait" = "reported", "Mapped Trait(s)" = "mapped", "Number of Variants" = "n_variants"))

} else {
  print("No PGS Catalog information available for all input scores")
}
```

### Variant matching

```{r, echo = FALSE}
params_df <- read.table("params.txt", sep = ":")
colnames(params_df) <- c("Parameter", "Value")
DT::datatable(params_df, caption = "Variant matching parameters")
```

```{r, echo = FALSE, message = FALSE, warning=FALSE}
log %>%
  mutate(match_type = forcats::fct_collapse(match_type, unmatched = "no match", other_level = "matched")) %>%
  group_by(dataset, accession, match_type) %>%
  count() %>%
  group_by(dataset, accession) %>%
  mutate(percent = round(n / sum(n) * 100, 1)) %>%
  arrange(accession, desc(percent)) %>%
  tidyr::pivot_wider(names_from = match_type, values_from = c(n, percent)) -> compat

# set row colour based on match type
background <- "percent_pass > 0.75 ? '#f1b6da' : value != 'else' ? '#b8e186' : ''"  
class(background) <- "JS_EVAL"

# DT::datatable(compat) %>%
#   DT::formatStyle(
#   'percent_pass',
#   target = 'row',
#   backgroundColor = background
# )

DT::datatable(compat, caption = "Variant matching statistics")

log %>%
  group_by(dataset, accession) %>%
  count(match_type, ambiguous) %>%
  mutate(ambiguous = ifelse(ambiguous == "", "true", ambiguous)) %>%
  mutate(percent = round(n / sum(n) * 100, 2)) %>%
  arrange(accession, desc(percent)) %>%
  DT::datatable(caption = "Matching details")
```


### Session information

```{r, echo = FALSE}
sessionInfo()
```

## Scores {.tabset}

```{r, echo = FALSE, message = FALSE}
read_scorefiles <- function(path) {
  dataset <- strsplit(path, split = "_")[[1]][[1]]
  df <- read.table(path, header = TRUE, comment.char = "")
  cols <- colnames(df) 
  cols[[1]] <- "IID"
  colnames(df) <- cols
  df$dataset <- dataset
  return(df)
}

scorefiles <- list.files(pattern = "*.sscore", all.files = TRUE)
combined_scorefile <- Reduce(dplyr::bind_rows, lapply(scorefiles, read_scorefiles))

combined_scorefile %>%
  group_by(dataset, IID) %>%
  summarise(across(matches("SUM$"), sum, na.rm = TRUE),
            DENOM_SUM = sum(DENOM)) %>%
  ungroup() %>%
  mutate(across(matches("SUM$"), ~ .x / DENOM_SUM, .names = "{.col}_AVG")) -> scores
```

### Summary

```{asis, echo = nrow(scores) < 50}
<div class="alert alert-warning", role="alert">
  <strong>⚠️ Warning: small sample size (n < 50)</strong> 
  <hr>
  <ul>
  <li>plink2 uses allele frequency data to <a href="https://www.cog-genomics.org/plink/2.0/score">mean-impute the dosages of missing genotypes</a></li>
  <li>Currently the pipeline disables mean-imputation in these small sample sets to make sure that the calculated PGS is as consistent with the genotype data as possible</li>
  <li>With a small sample size, the resulting score sums may be inconsistent between samples</li>
  <li>The average ([scorename]_AVG) may be more applicable as it calculates an average weighting over all genotypes present</li>
  </ul> 
  <hr>
  <p>
  In the future mean-imputation will be supported in small datasets using ancestry-matched reference datasets to ensure consistent calculation of score sums (e.g. 1000G Genomes).
  </p>
</div>
```

<div class="alert alert-success", role="alert">
<p>`r sum(grepl("*_SUM$", colnames(scores))) - 2` scores for `r nrow(scores)` samples processed</p>
</div>

```{r, echo = FALSE}
fn <- paste0("aggregated_scores_", gsub(" |:|-", "_", Sys.time()), ".txt.gz")
write.table(scores, gzfile(fn), col.names = TRUE, quote = FALSE, row.names = FALSE)
xfun::embed_file(fn, text = "Download all calculated scores", class = 'btn btn-primary btn-lg')
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
scores %>%
  ungroup() %>%
    select(-NAMED_ALLELE_DOSAGE_SUM) %>%
    select(IID, dataset, ends_with("SUM")) %>%
    group_by(IID, dataset) %>%
    tidyr::pivot_longer(cols=-group_cols()) %>%
    filter(name != "DENOM_SUM") %>%
    group_by(dataset, name) -> long_scores

group_keys(long_scores) %>%
  slice(1:6) -> score_keys

long_scores %>%
  inner_join(score_keys) %>%
  ggplot(aes(x = value, fill = dataset, alpha = 0.3)) +
      geom_density() +
      facet_wrap(~name, ncol = 2, scales = "free_x") +
      theme_bw() +
      theme(legend.position="none") +
      labs(x = "Score sum", y = "Count (of samples)", title = "Distribution of scores")
```



### Score extract

Below is a summary of a single score. It might be useful to double check the sample names and score names are what you expect.

```{r, echo = FALSE}
# only show one score in extract

scores %>%
  select(dataset, IID, ends_with("SUM")) %>%
  select(1:4) %>%
  DT::datatable(., caption = "Extract from calculated scores")
```

* See here for an explanation of [plink2 column names](https://www.cog-genomics.org/plink/2.0/formats#sscore).

